---
title: "Project 3 Data 607"
author: "Maryluz Cruz"
date: "10/13/2019"
output: html_document
---

## Text Analysis of Simplyhired, Glassdoor, and Monster

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

After all of the Data has been scraped from the Job websites and turned into .csv's, next we have to read in the .csv file and merge them together and then prepare them for text analysis. 


#Load packages

```{r}
require(dplyr)
require(rvest)
require(stringr)
require(tm)
require(SnowballC)
require(tidytext)
require(stringr)
require(textdata)
require(tidyverse)
```


Since all the comlumn names were different the column names were changed so that they all can be the same when we merge the three databases different databases. 

##Read in .csv of SimplyHired

```{r}
ltcancel<-read.csv("https://raw.githubusercontent.com/ltcancel/Project3/master/SimplyHiredJobs.csv")
colnames(ltcancel)<-c("Position", "Company","Location","Salary","URL","Job_Description")
str(ltcancel)
```

## Read in .csv of Glassdoor

```{r}
selshahawy<-read.csv("https://raw.githubusercontent.com/salma71/MSDS_2019/master/Fall2019/aquisition_management_607/project_3/jobs_detailsInfo.csv", stringsAsFactors = FALSE) 
colnames(selshahawy)<-c("Position", "Company","Location","URL","Job_Description")  
str(selshahawy)
```

## Read in .csv of Monster 

```{r}
ssufian<-read.csv("https://raw.githubusercontent.com/Luz917/data607project3_ssufian_monster_jobs/master/monsterjobs.csv", stringsAsFactors = FALSE) 
colnames(ssufian)<-c("Position", "Company","Location","Salary","URL","Job_Description")  
str(ssufian)
```

## Merge all the .csv's into one. 

Since we only can merge two at at time, we merge the first two .csvs into one. 
All the column names and rows are not identical so we have to set all = TRUE to make sure that they all merge no matter the number of columns or the number of rows. 

```{r}
twocsv<-merge(ltcancel,selshahawy,all= TRUE)
str(twocsv)
```

Here we merge the third .csv and all of the .csv's are merged together. 

```{r}
allcsv<-merge(twocsv,ssufian, all=TRUE)
str(allcsv)
```


## Prepare the csv for text analysis.


This step creates character vectors using corpus 

```{r}
descriptionofjobs = Corpus(VectorSource(allcsv$Job_Description))
```


```{r}
descriptionofjobs = tm_map(descriptionofjobs, content_transformer(tolower))
```


```{r}
descriptionofjobs=tm_map(descriptionofjobs, content_transformer(gsub), pattern="\\W",replace=" ")
```
```{r}
removeURL = function(x) gsub("http[^[:space:]]*", "", x)
descriptionofjobs <- tm_map(descriptionofjobs, content_transformer(removeURL))
```


```{r}
descriptionofjobs=tm_map(descriptionofjobs,removeNumbers)
```

```{r}
descriptionofjobs=tm_map(descriptionofjobs,removePunctuation)
```

```{r}
descriptionofjobs = tm_map(descriptionofjobs, removeWords, stopwords(kind = "english"))
```

```{r}
extraStopwords <- c(setdiff(stopwords('english'), c("r", "big")),"used", "will", "time", "can", "sex", "role", "new","can", "job", "etc", "one", "looking", "well","use","best","also", "high", "real", "please", "key", "able", "must", "like", "full", "include", "good", "non", "need","plus","day","year", "com", "want", "age","using", "help","apply")
```


```{r}
descriptionofjobs<- tm_map(descriptionofjobs, removeWords, extraStopwords)
```


```{r}
descriptionofjobs = tm_map (descriptionofjobs, stripWhitespace)
```



## Creating the Bag of Words 

```{r}
allwords<-DocumentTermMatrix(descriptionofjobs)
```


```{r}
sparsewords = removeSparseTerms(allwords,.10)
```

## Begin the analysis


Convert into a tidy table 

```{r}
tidywords<-tidy(allwords)
tidywords
```

```{r}
totalwords<-tidywords %>%
  count(term, sort= TRUE)
totalwords
```

```{r}
summaryofwords<-tidywords %>% 
  group_by(term) %>%
  summarize(total = sum(n()))%>%
  arrange(desc(total))
```


```{r}
totalwords<-left_join(totalwords, summaryofwords)
```


```{r}
tfrequency <-summaryofwords %>%
  group_by(term)%>%
  mutate(rank = row_number(), 'frequencyofterm' = n()/total)%>%
  arrange(desc(total))
tfrequency
```

```{r}
totalwords<-totalwords  %>% 
  bind_tf_idf(n,term,total)

totalwords
```

```{r}
totalwords %>%
  select(-total)%>%
  arrange(desc(tf_idf))
```

